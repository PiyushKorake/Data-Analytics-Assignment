{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_to_modeling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY0SJUCSY305"
      },
      "source": [
        "#### Copyright 2018 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q1hsKyBZDVu"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5tftaRtUcm7"
      },
      "source": [
        "#Intro to Modeling\n",
        "\n",
        "\n",
        "**Learning Objectives:**\n",
        "* Become familiar with pandas for handling small datasets\n",
        "* Use the tf.Estimator and Feature Column API to experiment with feature transformations\n",
        "* Use visualizations and run experiments to understand the value of feature transformations\n",
        "\n",
        "Please **make a copy** of this Colab notebook before starting this lab. To do so, choose **File**->**Save a copy in Drive**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT_bZ9E0ZWaN"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Let's start by importing our dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "wZ_T2SgDVKUH"
      },
      "source": [
        "%reset -f\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx4-PWE-VaD_"
      },
      "source": [
        "## Pandas, a helpful data analysis library for in-memory dataset\n",
        "\n",
        "We use a package called [Pandas](http://pandas.pydata.org/) for reading in our data, exploring our data and doing some basic processing. It is really helpful for datasets that fit in memory! And it has some nice integrations, as you will see.\n",
        "\n",
        "First we set up some options to control how items are displayed and the maximum number of rows to show when displaying a table.  Feel free to change this setup to whatever you'd like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKUIMcPCVRqv"
      },
      "source": [
        "# Set pandas output display to have one digit for decimal places and limit it to\n",
        "# printing 15 rows.\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "pd.options.display.max_rows = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_fTMztUVelY"
      },
      "source": [
        "### Load the dataset with pandas\n",
        "The car data set we will be using in this lab is provided as a comma separated file without a header row.  In order for each column to have a meaningful header name we must provide it.  We get the information about the columns from the [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/automobile).\n",
        "\n",
        "We will use the features of the car, to try to predict its price.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "Y38V73EgVYwt"
      },
      "source": [
        "# Provide the names for the columns since the CSV file with the data does\n",
        "# not have a header row.\n",
        "feature_names = ['symboling', 'normalized-losses', 'make', 'fuel-type',\n",
        "        'aspiration', 'num-doors', 'body-style', 'drive-wheels',\n",
        "        'engine-location', 'wheel-base', 'length', 'width', 'height', 'weight',\n",
        "        'engine-type', 'num-cylinders', 'engine-size', 'fuel-system', 'bore',\n",
        "        'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg',\n",
        "        'highway-mpg', 'price']\n",
        "\n",
        "\n",
        "# Load in the data from a CSV file that is comma separated.\n",
        "car_data = pd.read_csv('https://storage.googleapis.com/mledu-datasets/cars_data.csv',\n",
        "                        sep=',', names=feature_names, header=None, encoding='latin-1')\n",
        "\n",
        "\n",
        "# We'll then randomize the data, just to be sure not to get any pathological\n",
        "# ordering effects that might harm the performance of Stochastic Gradient\n",
        "# Descent.\n",
        "car_data = car_data.reindex(np.random.permutation(car_data.index))\n",
        "\n",
        "print(\"Data set loaded. Num examples: \", len(car_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAHZBtDlkmGa"
      },
      "source": [
        "This is a really small dataset! Only 205 examples.\n",
        "\n",
        "For simplicity in this codelab, we do not split the data further into training and validation. But you MUST do this on real datasets, or else you will overfit to your single dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ1HxLrOVqZk"
      },
      "source": [
        "## Task 0: Use pandas to explore and prepare the data\n",
        "\n",
        "- Use Pandas to inspect the data and manually curate a list of numeric_feature_names and categorical_feature_names.\n",
        "\n",
        "\n",
        "Useful functions:\n",
        "- `type()` called on any Python object describes the type of the object\n",
        "- `dataframe[4:7]` pulls out rows 4, 5, 6 in a Pandas dataframe\n",
        "- `dataframe[['mycol1', 'mycol2']]` pulls out the two requested columns into a new Pandas dataframe\n",
        "- `dataframe['mycol1']` returns a Pandas series -- not a dataframe!\n",
        "- `dataframe.describe()` prints out statistics for each dataframe column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfeHYeMf7PwQ"
      },
      "source": [
        "car_data[4:7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "VsOUrVozoe9u"
      },
      "source": [
        "LABEL = 'price'\n",
        "\n",
        "numeric_feature_names = car_data[['symboling','normalized-losses','wheel-base','engine-size','bore','stroke','compression-ratio','horsepower','peak-rpm','city-mpg','highway-mpg','price']]\n",
        "categorical_feature_names = list(set(feature_names) - set(numeric_feature_names) - set([LABEL]))\n",
        "\n",
        "# The correct solution will pass these assert statements.\n",
        "assert len(numeric_feature_names) == 15\n",
        "assert len(categorical_feature_names) == 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "lLFkHgBm8O1Y"
      },
      "source": [
        "#@title Solution (to view code, from cell's menu, select Form -> Show Code)\n",
        "numeric_feature_names = ['symboling', 'normalized-losses', 'wheel-base',\n",
        "        'length', 'width', 'height', 'weight', 'engine-size', 'horsepower',\n",
        "        'peak-rpm', 'city-mpg', 'highway-mpg', 'bore', 'stroke',\n",
        "         'compression-ratio']\n",
        "\n",
        "categorical_feature_names = list(set(feature_names) - set(numeric_feature_names) - set([LABEL]))\n",
        "\n",
        "assert len(numeric_feature_names) == 15\n",
        "assert len(categorical_feature_names) == 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nabeQFGBpDEN"
      },
      "source": [
        "# Run to inspect numeric features.\n",
        "car_data[numeric_feature_names]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1ss9Q7mpiBy"
      },
      "source": [
        "# Run to inspect categorical features.\n",
        "car_data[categorical_feature_names]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OjDegBgqNnu"
      },
      "source": [
        "# Coerce the numeric features to numbers. This is necessary because the model\n",
        "# crashes because not all the values are numeric.\n",
        "for feature_name in numeric_feature_names + [LABEL]:\n",
        "  car_data[feature_name] = pd.to_numeric(car_data[feature_name], errors='coerce')\n",
        "\n",
        "# Fill missing values with 0.\n",
        "# Is this an OK thing to do? You may want to come back and revisit this decision later.\n",
        "car_data.fillna(0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq-t-8GPvnCW"
      },
      "source": [
        "## Task 1: Make your best model with numeric features. No normalization allowed.\n",
        "\n",
        "Modify the model provided below to achieve the lowest eval loss. You may want to change various hyperparameters:\n",
        "- learning rate\n",
        "- choice of optimizer\n",
        "- hidden layer dimensions -- make sure your choice here makes sense given the number of training examples\n",
        "- batch size\n",
        "- num training steps\n",
        "- (anything else you can think of changing)\n",
        "\n",
        "Do not use the `normalizer_fn` arg on `numeric_column`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH6KJp-4-E_Q"
      },
      "source": [
        "# This code \"works\", but because of bad hyperparameter choices it gets NaN loss\n",
        "# during training. Try fixing this.\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "print(numeric_feature_names)\n",
        "x_df = car_data[numeric_feature_names]\n",
        "y_series = car_data['price']\n",
        "\n",
        "# Create input_fn's so that the estimator knows how to read in your data.\n",
        "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "\n",
        "eval_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "# Feature columns allow the model to parse the data, perform common\n",
        "# preprocessing, and automatically generate an input layer for the tf.Estimator.\n",
        "model_feature_columns = [\n",
        "    tf.feature_column.numeric_column(feature_name) for feature_name in numeric_feature_names\n",
        "]\n",
        "print('model_feature_columns', model_feature_columns)\n",
        "\n",
        "est = tf.estimator.DNNRegressor(\n",
        "    feature_columns=model_feature_columns,\n",
        "    hidden_units=[64],\n",
        "    optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.01),\n",
        "  )\n",
        "\n",
        "# TRAIN\n",
        "num_print_statements = 10\n",
        "num_training_steps = 10000\n",
        "for _ in range(num_print_statements):\n",
        "  est.train(train_input_fn, steps=num_training_steps // num_print_statements)\n",
        "  scores = est.evaluate(eval_input_fn)\n",
        "\n",
        "  # The `scores` dictionary has several metrics automatically generated by the\n",
        "  # canned Estimator.\n",
        "  # `average_loss` is the average loss for an individual example.\n",
        "  # `loss` is the summed loss for the batch.\n",
        "  # In addition to these scalar losses, you may find the visualization functions\n",
        "  # in the next cell helpful for debugging model quality.\n",
        "  print('scores', scores)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "3ptcfj_9Xi9M"
      },
      "source": [
        "#@title Possible solution\n",
        "# Here is one possible solution:\n",
        "# The only necessary change to fix the NaN training loss was the choice of optimizer.\n",
        "\n",
        "# Changing other parameters could improve model quality, but take it with a\n",
        "# grain of salt. The dataset is very small.\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "print(numeric_feature_names)\n",
        "x_df = car_data[numeric_feature_names]\n",
        "y_series = car_data['price']\n",
        "\n",
        "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "\n",
        "eval_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "# Feature columns allow the model to parse the data, perform common\n",
        "# preprocessing, and automatically generate an input layer for the tf.Estimator.\n",
        "model_feature_columns = [\n",
        "    tf.feature_column.numeric_column(feature_name) for feature_name in numeric_feature_names\n",
        "]\n",
        "print('model_feature_columns', model_feature_columns)\n",
        "\n",
        "est = tf.estimator.DNNRegressor(\n",
        "    feature_columns=model_feature_columns,\n",
        "    hidden_units=[64],\n",
        "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.01),\n",
        "  )\n",
        "\n",
        "# TRAIN\n",
        "num_print_statements = 10\n",
        "num_training_steps = 10000\n",
        "for _ in range(num_print_statements):\n",
        "  est.train(train_input_fn, steps=num_training_steps // num_print_statements)\n",
        "  scores = est.evaluate(eval_input_fn)\n",
        "\n",
        "  # The `scores` dictionary has several metrics automatically generated by the\n",
        "  # canned Estimator.\n",
        "  # `average_loss` is the average loss for an individual example.\n",
        "  # `loss` is the summed loss for the batch.\n",
        "  # In addition to these scalar losses, you may find the visualization functions\n",
        "  # in the next cell helpful for debugging model quality.\n",
        "  print('scores', scores)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rxto3DwsjYw4"
      },
      "source": [
        "### Visualize your model's predictions\n",
        "\n",
        "After you have a trained model, it may be helpful to understand how your model's inference differs from the actual data.\n",
        "\n",
        "This helper function `scatter_plot_inference` does that for you. Real data is in grey. Your model's predictions are in orange.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGSXwX2fju1N"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def scatter_plot_inference_grid(est, x_df, feature_names):\n",
        "  \"\"\"Plots the predictions of the model against each feature.\n",
        "\n",
        "  Args:\n",
        "    est: The trained tf.Estimator.\n",
        "    x_df: The pandas dataframe with the input data (used to create\n",
        "      predict_input_fn).\n",
        "    feature_names: An iterable of string feature names to plot.\n",
        "  \"\"\"\n",
        "  def scatter_plot_inference(axis,\n",
        "                             x_axis_feature_name,\n",
        "                             y_axis_feature_name,\n",
        "                             predictions):\n",
        "    \"\"\"Generate one subplot.\"\"\"\n",
        "    # Plot the real data in grey.\n",
        "    y_axis_feature_name = 'price'\n",
        "    axis.set_ylabel(y_axis_feature_name)\n",
        "    axis.set_xlabel(x_axis_feature_name)\n",
        "    axis.scatter(car_data[x_axis_feature_name],\n",
        "                 car_data[y_axis_feature_name],\n",
        "                 c='grey')\n",
        "\n",
        "    # Plot the predicted data in orange.\n",
        "    axis.scatter(car_data[x_axis_feature_name], predictions, c='orange')\n",
        "\n",
        "  predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "  predictions = [\n",
        "    x['predictions'][0]\n",
        "    for x in est.predict(predict_input_fn)\n",
        "  ]\n",
        "\n",
        "  num_cols = 3\n",
        "  num_rows = int(math.ceil(len(feature_names)/float(num_cols)))\n",
        "  f, axarr = plt.subplots(num_rows, num_cols)\n",
        "  size = 4.5\n",
        "  f.set_size_inches(num_cols*size, num_rows*size)\n",
        "\n",
        "  for i, feature_name in enumerate(numeric_feature_names):\n",
        "    axis = axarr[int(i/num_cols), i%num_cols]\n",
        "    scatter_plot_inference(axis, feature_name, 'price', predictions)\n",
        "  plt.show()\n",
        "\n",
        "scatter_plot_inference_grid(est, x_df, numeric_feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBZI8f_8Yfph"
      },
      "source": [
        "## Task 2: Take your best numeric model from earlier. Add normalization.\n",
        "\n",
        "### Add normalization to your best numeric model from earlier\n",
        "\n",
        "- You decide what type of normalization to add, and for which features\n",
        "- You will need to use the `normalizer_fn` arg on [`numeric_column`](https://g3doc.corp.google.com/learning/brain/public/g3doc/api_docs/python/tf/feature_column/numeric_column.md?cl=head)\n",
        "    - An example of a silly normalizer_fn that shifts inputs down by 1, and then negates the value:\n",
        "    \n",
        "         normalizer_fn = lambda x: tf.neg(tf.subtract(x, 1))\n",
        "\n",
        "- You may find these pandas functions helpful:\n",
        "    - dataframe.mean()['your_feature_name']\n",
        "    - dataframe.std()['your_feature_name']\n",
        "- You will need to retune the hyperparameters from earlier.\n",
        "\n",
        "\n",
        "**Does normalization improve model quality on this dataset? Why or why not?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY_C_QgcZg1-"
      },
      "source": [
        "# This 1D visualization of each numeric feature might inform your normalization\n",
        "# decisions.\n",
        "for feature_name in numeric_feature_names:\n",
        "  car_data.hist(column=feature_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiEpDZKSj8pN"
      },
      "source": [
        "###Train your model with numeric features + normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c30Y6IiR8iVn"
      },
      "source": [
        "## Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxYJy71zaZsy"
      },
      "source": [
        "#@title Possible solution\n",
        "# This does Z-score normalization since the distributions for most features looked\n",
        "# roughly normally distributed.\n",
        "\n",
        "# Z-score normalization subtracts the mean and divides by the standard deviation,\n",
        "# to give a roughly standard normal distribution (mean = 0, std = 1) under a\n",
        "# normal distribution assumption. Epsilon prevents divide by zero.\n",
        "\n",
        "# With normalization, are you able to get the model working with\n",
        "# GradientDescentOptimizer? Z-score normalization doesn't seem to be able to get\n",
        "# SGD working. Maybe a different type of normalization would?\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "print(numeric_feature_names)\n",
        "x_df = car_data[numeric_feature_names]\n",
        "y_series = car_data['price']\n",
        "\n",
        "train_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    num_epochs=None,\n",
        "    shuffle=True)\n",
        "\n",
        "eval_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    y=y_series,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "predict_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
        "    x=x_df,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "\n",
        "# Epsilon prevents divide by zero.\n",
        "epsilon = 0.000001\n",
        "model_feature_columns = [\n",
        "    tf.feature_column.numeric_column(feature_name,\n",
        "                                     normalizer_fn=lambda val: (val - x_df.mean()[feature_name]) / (epsilon + x_df.std()[feature_name]))\n",
        "    for feature_name in numeric_feature_names\n",
        "]\n",
        "print('model_feature_columns', model_feature_columns)\n",
        "\n",
        "est = tf.estimator.DNNRegressor(\n",
        "    feature_columns=model_feature_columns,\n",
        "    hidden_units=[64],\n",
        "    optimizer=tf.train.AdagradOptimizer(learning_rate=0.01),\n",
        "  )\n",
        "\n",
        "# TRAIN\n",
        "num_print_statements = 10\n",
        "num_training_steps = 10000\n",
        "for _ in range(num_print_statements):\n",
        "  est.train(train_input_fn, steps=num_training_steps // num_print_statements)\n",
        "  scores = est.evaluate(eval_input_fn)\n",
        "\n",
        "  # The `scores` dictionary has several metrics automatically generated by the\n",
        "  # canned Estimator.\n",
        "  # `average_loss` is the average loss for an individual example.\n",
        "  # `loss` is the summed loss for the batch.\n",
        "  # In addition to these scalar losses, you may find the visualization functions\n",
        "  # in the next cell helpful for debugging model quality.\n",
        "  print('scores', scores)\n",
        "\n",
        "scatter_plot_inference_grid(est, x_df, numeric_feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fruh0Qj5_Bos"
      },
      "source": [
        "## Task 3: Make your best model using only categorical features\n",
        "\n",
        "- Look at the possible feature columns for categorical features. They begin with `categorical_column_with_` in go/tf-ops.\n",
        "- You may find `dataframe[categorical_feature_names].unique()` helpful.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "-udhHnNS2WvN"
      },
      "source": [
        "## Your code goes here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EftIzPAI9RJj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f98449a-fa41-4dcb-8029-b9d588681cc3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, regularizers\n",
        "import numpy as np\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 16\n",
        "\n",
        "# Prepare data (categorical features remain unnormalized, numeric features normalized inside the model)\n",
        "x_df = car_data[numeric_feature_names]\n",
        "y_series = car_data['price']\n",
        "\n",
        "# Create Interaction Terms (Multiply pairs of features)\n",
        "# Example interactions: Engine Size × Weight, City MPG × Highway MPG\n",
        "x_df['engine_size_weight'] = x_df['engine-size'] * x_df['weight']\n",
        "x_df['city_mpg_highway_mpg'] = x_df['city-mpg'] * x_df['highway-mpg']\n",
        "\n",
        "# Add these interaction terms to the model input\n",
        "numeric_feature_names_with_interactions = numeric_feature_names + ['engine_size_weight', 'city_mpg_highway_mpg']\n",
        "\n",
        "# Build a more complex DNN model using Keras with regularization and dropout\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=(len(numeric_feature_names_with_interactions),)),  # Input layer (shape inferred from data)\n",
        "\n",
        "    # First hidden layer with 128 neurons and L2 regularization\n",
        "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    layers.Dropout(0.2),  # Dropout to reduce overfitting\n",
        "\n",
        "    # Second hidden layer with 64 neurons\n",
        "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    # Third hidden layer with 32 neurons\n",
        "    layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    layers.Dropout(0.2),\n",
        "\n",
        "    # Output layer for regression\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model with a lower learning rate (try even lower, e.g., 0.0001)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Early stopping to prevent overfitting\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_df[numeric_feature_names_with_interactions].values, y_series.values,  # Ensure input is in numpy format\n",
        "    epochs=100,  # Set epochs to 100\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,  # Use 20% of the data for validation\n",
        "    callbacks=[early_stopping]  # Apply early stopping\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "eval_dataset = tf.data.Dataset.from_tensor_slices((x_df[numeric_feature_names_with_interactions].values, y_series))\n",
        "eval_dataset = eval_dataset.batch(batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, mae = model.evaluate(eval_dataset, steps=len(x_df) // batch_size)\n",
        "\n",
        "print(f\"\\n✅ Test MSE (Loss): {loss:.2f}\")\n",
        "print(f\"✅ Test MAE: {mae:.2f}\")\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-63d2df8f8b51>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x_df['engine_size_weight'] = x_df['engine-size'] * x_df['weight']\n",
            "<ipython-input-40-63d2df8f8b51>:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x_df['city_mpg_highway_mpg'] = x_df['city-mpg'] * x_df['highway-mpg']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - loss: 249583808.0000 - mae: 13359.9932 - val_loss: 264545648.0000 - val_mae: 13579.4756\n",
            "Epoch 2/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 256490384.0000 - mae: 13534.0781 - val_loss: 264523904.0000 - val_mae: 13578.8389\n",
            "Epoch 3/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 223031936.0000 - mae: 12440.1191 - val_loss: 264492304.0000 - val_mae: 13577.9082\n",
            "Epoch 4/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 246774096.0000 - mae: 13294.5654 - val_loss: 264445456.0000 - val_mae: 13576.5518\n",
            "Epoch 5/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 198734208.0000 - mae: 12310.2080 - val_loss: 264374464.0000 - val_mae: 13574.5381\n",
            "Epoch 6/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 233079040.0000 - mae: 12869.2080 - val_loss: 264262064.0000 - val_mae: 13571.4434\n",
            "Epoch 7/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 222968736.0000 - mae: 12690.7285 - val_loss: 264092096.0000 - val_mae: 13566.8945\n",
            "Epoch 8/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 234409168.0000 - mae: 13067.6924 - val_loss: 263831728.0000 - val_mae: 13560.0439\n",
            "Epoch 9/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 214138208.0000 - mae: 12476.6016 - val_loss: 263448896.0000 - val_mae: 13550.1055\n",
            "Epoch 10/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 224729824.0000 - mae: 12899.9453 - val_loss: 262891888.0000 - val_mae: 13535.9785\n",
            "Epoch 11/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 207803680.0000 - mae: 12481.9326 - val_loss: 262106656.0000 - val_mae: 13516.3477\n",
            "Epoch 12/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 211034704.0000 - mae: 12324.9404 - val_loss: 261076192.0000 - val_mae: 13490.8125\n",
            "Epoch 13/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 233129632.0000 - mae: 13048.5215 - val_loss: 259731136.0000 - val_mae: 13457.6191\n",
            "Epoch 14/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 203360640.0000 - mae: 12297.8047 - val_loss: 258034496.0000 - val_mae: 13415.6094\n",
            "Epoch 15/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 231956016.0000 - mae: 12819.7754 - val_loss: 255721696.0000 - val_mae: 13359.4346\n",
            "Epoch 16/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 201153168.0000 - mae: 12192.1406 - val_loss: 252854496.0000 - val_mae: 13289.4150\n",
            "Epoch 17/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 263681680.0000 - mae: 13474.1592 - val_loss: 249375648.0000 - val_mae: 13204.1436\n",
            "Epoch 18/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 186957152.0000 - mae: 11743.4072 - val_loss: 245287888.0000 - val_mae: 13102.9736\n",
            "Epoch 19/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 183831440.0000 - mae: 11830.1250 - val_loss: 240168368.0000 - val_mae: 12977.7344\n",
            "Epoch 20/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 188760192.0000 - mae: 11838.4102 - val_loss: 233919216.0000 - val_mae: 12823.5166\n",
            "Epoch 21/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 187742160.0000 - mae: 11806.2432 - val_loss: 227435952.0000 - val_mae: 12657.6123\n",
            "Epoch 22/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 171441504.0000 - mae: 11209.8066 - val_loss: 220108576.0000 - val_mae: 12464.8691\n",
            "Epoch 23/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 174486288.0000 - mae: 11447.0430 - val_loss: 211262992.0000 - val_mae: 12231.0088\n",
            "Epoch 24/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 190391808.0000 - mae: 11881.7881 - val_loss: 201663632.0000 - val_mae: 11967.9355\n",
            "Epoch 25/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 154212736.0000 - mae: 10841.0293 - val_loss: 191863328.0000 - val_mae: 11687.5645\n",
            "Epoch 26/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 134148928.0000 - mae: 10224.8154 - val_loss: 180950624.0000 - val_mae: 11361.7412\n",
            "Epoch 27/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 138391872.0000 - mae: 10222.0527 - val_loss: 168877536.0000 - val_mae: 10984.9043\n",
            "Epoch 28/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 138722544.0000 - mae: 10055.7988 - val_loss: 156776928.0000 - val_mae: 10581.0674\n",
            "Epoch 29/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 116469072.0000 - mae: 9311.8691 - val_loss: 145373584.0000 - val_mae: 10164.6387\n",
            "Epoch 30/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 93506328.0000 - mae: 8496.2969 - val_loss: 133972952.0000 - val_mae: 9706.6191\n",
            "Epoch 31/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 97829136.0000 - mae: 8685.6621 - val_loss: 122442464.0000 - val_mae: 9196.2539\n",
            "Epoch 32/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 92532864.0000 - mae: 8357.0381 - val_loss: 112406928.0000 - val_mae: 8685.9561\n",
            "Epoch 33/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 84289248.0000 - mae: 7796.7280 - val_loss: 103961536.0000 - val_mae: 8181.4575\n",
            "Epoch 34/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 58197320.0000 - mae: 6518.5620 - val_loss: 97456224.0000 - val_mae: 7740.8408\n",
            "Epoch 35/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 71659696.0000 - mae: 7007.7432 - val_loss: 92092568.0000 - val_mae: 7433.1899\n",
            "Epoch 36/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 57174172.0000 - mae: 6408.1284 - val_loss: 88255304.0000 - val_mae: 7160.4194\n",
            "Epoch 37/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 48585992.0000 - mae: 6006.4258 - val_loss: 85389032.0000 - val_mae: 6906.8521\n",
            "Epoch 38/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 44485496.0000 - mae: 5610.9053 - val_loss: 83373552.0000 - val_mae: 6688.7334\n",
            "Epoch 39/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 39630432.0000 - mae: 5280.4683 - val_loss: 81988080.0000 - val_mae: 6539.0151\n",
            "Epoch 40/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 35819740.0000 - mae: 4883.3213 - val_loss: 80632072.0000 - val_mae: 6420.2012\n",
            "Epoch 41/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 41552100.0000 - mae: 5307.8818 - val_loss: 79447528.0000 - val_mae: 6324.9185\n",
            "Epoch 42/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 44458692.0000 - mae: 5481.4780 - val_loss: 78414424.0000 - val_mae: 6260.2910\n",
            "Epoch 43/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 39374952.0000 - mae: 5099.1904 - val_loss: 77577280.0000 - val_mae: 6205.5757\n",
            "Epoch 44/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 44926752.0000 - mae: 5340.0830 - val_loss: 76814224.0000 - val_mae: 6175.5083\n",
            "Epoch 45/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 45498856.0000 - mae: 5320.0000 - val_loss: 75986528.0000 - val_mae: 6101.0815\n",
            "Epoch 46/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 41596276.0000 - mae: 5210.8022 - val_loss: 75232464.0000 - val_mae: 6053.6558\n",
            "Epoch 47/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 34016740.0000 - mae: 4856.8862 - val_loss: 74599696.0000 - val_mae: 6001.7583\n",
            "Epoch 48/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 46587052.0000 - mae: 5335.4634 - val_loss: 73939072.0000 - val_mae: 5948.9946\n",
            "Epoch 49/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 37755756.0000 - mae: 4961.5200 - val_loss: 73295216.0000 - val_mae: 5905.3945\n",
            "Epoch 50/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 43660332.0000 - mae: 5342.3267 - val_loss: 72604208.0000 - val_mae: 5868.5234\n",
            "Epoch 51/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 35473524.0000 - mae: 4637.4702 - val_loss: 71764144.0000 - val_mae: 5838.7271\n",
            "Epoch 52/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 37138072.0000 - mae: 4523.3228 - val_loss: 71115184.0000 - val_mae: 5787.3140\n",
            "Epoch 53/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 37008176.0000 - mae: 4892.9326 - val_loss: 70364640.0000 - val_mae: 5769.5737\n",
            "Epoch 54/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 39673648.0000 - mae: 4864.7129 - val_loss: 69630616.0000 - val_mae: 5732.7144\n",
            "Epoch 55/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 42941672.0000 - mae: 4999.1313 - val_loss: 69044272.0000 - val_mae: 5674.6479\n",
            "Epoch 56/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 43816792.0000 - mae: 4976.5679 - val_loss: 68356848.0000 - val_mae: 5643.9385\n",
            "Epoch 57/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 40198008.0000 - mae: 4915.7842 - val_loss: 67751208.0000 - val_mae: 5613.1860\n",
            "Epoch 58/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 34140792.0000 - mae: 4486.7041 - val_loss: 67059076.0000 - val_mae: 5587.4712\n",
            "Epoch 59/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 31390470.0000 - mae: 4325.3306 - val_loss: 66272200.0000 - val_mae: 5571.4858\n",
            "Epoch 60/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 42136944.0000 - mae: 5130.4849 - val_loss: 65567664.0000 - val_mae: 5535.1973\n",
            "Epoch 61/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29628688.0000 - mae: 4220.9990 - val_loss: 64889720.0000 - val_mae: 5503.3306\n",
            "Epoch 62/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29058200.0000 - mae: 4160.0796 - val_loss: 64282692.0000 - val_mae: 5456.2217\n",
            "Epoch 63/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28858680.0000 - mae: 4165.3281 - val_loss: 63694072.0000 - val_mae: 5400.4150\n",
            "Epoch 64/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28973356.0000 - mae: 4395.2900 - val_loss: 63033144.0000 - val_mae: 5357.8950\n",
            "Epoch 65/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 38386092.0000 - mae: 4771.2529 - val_loss: 62437412.0000 - val_mae: 5329.9971\n",
            "Epoch 66/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30867712.0000 - mae: 4426.6191 - val_loss: 61826860.0000 - val_mae: 5296.3062\n",
            "Epoch 67/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 33649648.0000 - mae: 4575.9033 - val_loss: 61143232.0000 - val_mae: 5235.9229\n",
            "Epoch 68/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 33163850.0000 - mae: 4394.3345 - val_loss: 60355760.0000 - val_mae: 5176.3252\n",
            "Epoch 69/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 36950884.0000 - mae: 4382.1353 - val_loss: 59602052.0000 - val_mae: 5176.3525\n",
            "Epoch 70/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 26588280.0000 - mae: 3974.9668 - val_loss: 59080060.0000 - val_mae: 5143.1611\n",
            "Epoch 71/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 31316668.0000 - mae: 4226.3970 - val_loss: 58529544.0000 - val_mae: 5093.0635\n",
            "Epoch 72/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 25739850.0000 - mae: 4028.2219 - val_loss: 58059256.0000 - val_mae: 5066.7563\n",
            "Epoch 73/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 27141228.0000 - mae: 3994.3308 - val_loss: 57471824.0000 - val_mae: 5048.0669\n",
            "Epoch 74/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 29674012.0000 - mae: 4097.4297 - val_loss: 56932516.0000 - val_mae: 5043.2529\n",
            "Epoch 75/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 25322672.0000 - mae: 3750.8711 - val_loss: 56450948.0000 - val_mae: 4994.7715\n",
            "Epoch 76/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29569872.0000 - mae: 4235.1470 - val_loss: 56021892.0000 - val_mae: 4936.6738\n",
            "Epoch 77/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 30398570.0000 - mae: 4177.3779 - val_loss: 55627340.0000 - val_mae: 4890.6807\n",
            "Epoch 78/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 27301420.0000 - mae: 4116.6929 - val_loss: 55166672.0000 - val_mae: 4848.8618\n",
            "Epoch 79/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 25800064.0000 - mae: 3729.7825 - val_loss: 54632952.0000 - val_mae: 4814.2886\n",
            "Epoch 80/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 23236054.0000 - mae: 3787.0615 - val_loss: 54090652.0000 - val_mae: 4780.6157\n",
            "Epoch 81/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 23042958.0000 - mae: 3761.0229 - val_loss: 53590616.0000 - val_mae: 4742.0474\n",
            "Epoch 82/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 28618122.0000 - mae: 4033.3147 - val_loss: 53034320.0000 - val_mae: 4731.7700\n",
            "Epoch 83/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 25033856.0000 - mae: 3900.9446 - val_loss: 52537088.0000 - val_mae: 4690.4351\n",
            "Epoch 84/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 24548498.0000 - mae: 3829.1479 - val_loss: 52119744.0000 - val_mae: 4642.6191\n",
            "Epoch 85/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 24746414.0000 - mae: 3635.8994 - val_loss: 51675656.0000 - val_mae: 4599.5972\n",
            "Epoch 86/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 31311192.0000 - mae: 4169.0991 - val_loss: 51172548.0000 - val_mae: 4581.0571\n",
            "Epoch 87/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25633718.0000 - mae: 3849.3303 - val_loss: 50646636.0000 - val_mae: 4569.0923\n",
            "Epoch 88/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 21751654.0000 - mae: 3531.9497 - val_loss: 50212552.0000 - val_mae: 4533.9683\n",
            "Epoch 89/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 23136648.0000 - mae: 3621.1702 - val_loss: 49908656.0000 - val_mae: 4459.3276\n",
            "Epoch 90/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 23828104.0000 - mae: 3839.5281 - val_loss: 49655296.0000 - val_mae: 4414.9004\n",
            "Epoch 91/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 27705368.0000 - mae: 4054.0540 - val_loss: 49259980.0000 - val_mae: 4401.2051\n",
            "Epoch 92/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 25959292.0000 - mae: 3803.6970 - val_loss: 48797416.0000 - val_mae: 4370.3022\n",
            "Epoch 93/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 24781890.0000 - mae: 3699.3901 - val_loss: 48364856.0000 - val_mae: 4325.7598\n",
            "Epoch 94/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 19841342.0000 - mae: 3528.8906 - val_loss: 47978632.0000 - val_mae: 4294.7178\n",
            "Epoch 95/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 24197528.0000 - mae: 3721.3638 - val_loss: 47571720.0000 - val_mae: 4260.1982\n",
            "Epoch 96/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 22536650.0000 - mae: 3660.6318 - val_loss: 47203384.0000 - val_mae: 4236.7686\n",
            "Epoch 97/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29516530.0000 - mae: 4030.7356 - val_loss: 46778552.0000 - val_mae: 4229.8975\n",
            "Epoch 98/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 27392502.0000 - mae: 3938.4834 - val_loss: 46351080.0000 - val_mae: 4215.2100\n",
            "Epoch 99/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20500902.0000 - mae: 3484.1418 - val_loss: 46045304.0000 - val_mae: 4178.9966\n",
            "Epoch 100/100\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 16535651.0000 - mae: 3104.1455 - val_loss: 45749752.0000 - val_mae: 4146.2056\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17464780.0000 - mae: 3068.2297  \n",
            "\n",
            "✅ Test MSE (Loss): 24915520.00\n",
            "✅ Test MAE: 3403.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyBH5Wai_HTD"
      },
      "source": [
        "## Task 4: Using all the features, make the best model that you can make\n",
        "\n",
        "With all the features combined, your model should perform better than your earlier models using numerical and categorical models alone. Tune your model until that is the case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNfCzC-q8edv"
      },
      "source": [
        "## Your code goes here"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obWuUXs1e4k4",
        "outputId": "638a119d-c111-4c13-f894-8be49eee61c1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmNe8qT1e-Wm",
        "outputId": "854b2b03-7f86-4e18-8556-e562157960d2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras) (4.13.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmaGHWFVGKMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670357ad-7e4c-4642-cf9a-7bbe4b12b1e5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Step 1: Prepare data (polynomial features for interaction terms)\n",
        "x_df = car_data[numeric_feature_names]\n",
        "y_series = car_data['price']\n",
        "\n",
        "# Create polynomial features up to degree 2 (interaction terms included)\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=False)\n",
        "x_poly = poly.fit_transform(x_df)\n",
        "\n",
        "# Update the feature names to include interaction terms\n",
        "poly_feature_names = poly.get_feature_names_out(input_features=numeric_feature_names)\n",
        "x_poly_df = pd.DataFrame(x_poly, columns=poly_feature_names)\n",
        "\n",
        "# Step 2: Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_poly_df, y_series, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Define the model architecture\n",
        "def create_model(learning_rate=0.001, dropout_rate=0.2, neurons=64):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.Input(shape=(X_train.shape[1],)),\n",
        "        layers.Dense(neurons, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(neurons * 2, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(neurons, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "        layers.Dense(1)  # Output layer for regression\n",
        "    ])\n",
        "    model.compile(optimizer=RMSprop(learning_rate=learning_rate),\n",
        "                  loss='mean_squared_error', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "# Step 4: Set up KFold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold = 1\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    print(f\"Training on fold {fold}...\")\n",
        "\n",
        "    # Split the data into training and validation sets for this fold\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    # Step 5: Train the model on each fold\n",
        "    model = create_model(learning_rate=0.001, neurons=128, dropout_rate=0.3)\n",
        "    model.fit(X_train_fold, y_train_fold, epochs=50, batch_size=32, validation_data=(X_val_fold, y_val_fold), verbose=0)\n",
        "\n",
        "    # Step 6: Evaluate the model on the validation set\n",
        "    val_loss, val_mae = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
        "    print(f\"Fold {fold} - Validation Loss: {val_loss:.2f}, Validation MAE: {val_mae:.2f}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# Step 7: Evaluate the model on the test set\n",
        "final_model = create_model(learning_rate=0.001, neurons=128, dropout_rate=0.3)\n",
        "final_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the final model\n",
        "loss, mae = final_model.evaluate(X_test, y_test)\n",
        "print(f\"\\n✅ Final Model Test MSE (Loss): {loss:.2f}\")\n",
        "print(f\"✅ Final Model Test MAE: {mae:.2f}\")\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on fold 1...\n",
            "Fold 1 - Validation Loss: 27290182.00, Validation MAE: 4406.64\n",
            "Training on fold 2...\n",
            "Fold 2 - Validation Loss: 55297600.00, Validation MAE: 5945.39\n",
            "Training on fold 3...\n",
            "Fold 3 - Validation Loss: 87673920.00, Validation MAE: 5587.71\n",
            "Training on fold 4...\n",
            "Fold 4 - Validation Loss: 84072000.00, Validation MAE: 6694.12\n",
            "Training on fold 5...\n",
            "Fold 5 - Validation Loss: 31374146.00, Validation MAE: 4736.01\n",
            "Epoch 1/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 294787968.0000 - mae: 14299.7812 - val_loss: 201190496.0000 - val_mae: 12013.0938\n",
            "Epoch 2/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 293670432.0000 - mae: 14398.4121 - val_loss: 199693232.0000 - val_mae: 11977.3213\n",
            "Epoch 3/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 253156208.0000 - mae: 13538.0078 - val_loss: 196044432.0000 - val_mae: 11893.6318\n",
            "Epoch 4/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 269891072.0000 - mae: 13806.1602 - val_loss: 190245712.0000 - val_mae: 11759.1494\n",
            "Epoch 5/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 242665984.0000 - mae: 13052.0059 - val_loss: 180292480.0000 - val_mae: 11524.3213\n",
            "Epoch 6/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 224450736.0000 - mae: 12852.4590 - val_loss: 168475312.0000 - val_mae: 11229.4121\n",
            "Epoch 7/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 207208832.0000 - mae: 12356.6641 - val_loss: 153807520.0000 - val_mae: 10833.2842\n",
            "Epoch 8/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 178468768.0000 - mae: 11384.8281 - val_loss: 138025792.0000 - val_mae: 10350.3926\n",
            "Epoch 9/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 149419616.0000 - mae: 10448.5498 - val_loss: 121824520.0000 - val_mae: 9864.8838\n",
            "Epoch 10/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 131474608.0000 - mae: 9776.9102 - val_loss: 107655616.0000 - val_mae: 9431.0938\n",
            "Epoch 11/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 107484632.0000 - mae: 8740.6445 - val_loss: 95397032.0000 - val_mae: 8896.1055\n",
            "Epoch 12/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 94947664.0000 - mae: 8077.4990 - val_loss: 88136960.0000 - val_mae: 8426.0801\n",
            "Epoch 13/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 92398376.0000 - mae: 7856.2954 - val_loss: 84931840.0000 - val_mae: 8180.0103\n",
            "Epoch 14/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 89945880.0000 - mae: 7727.1885 - val_loss: 83763688.0000 - val_mae: 8136.0542\n",
            "Epoch 15/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 100581536.0000 - mae: 8260.1504 - val_loss: 83093904.0000 - val_mae: 8151.1865\n",
            "Epoch 16/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 92962160.0000 - mae: 7825.7759 - val_loss: 80684296.0000 - val_mae: 7976.9224\n",
            "Epoch 17/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 81553328.0000 - mae: 7519.2036 - val_loss: 79694960.0000 - val_mae: 7943.7905\n",
            "Epoch 18/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 76375272.0000 - mae: 7032.5537 - val_loss: 76407864.0000 - val_mae: 7813.4819\n",
            "Epoch 19/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 79918240.0000 - mae: 7275.0293 - val_loss: 75619192.0000 - val_mae: 7758.1099\n",
            "Epoch 20/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 76828048.0000 - mae: 7106.8066 - val_loss: 74458456.0000 - val_mae: 7693.9365\n",
            "Epoch 21/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 73653696.0000 - mae: 7017.0244 - val_loss: 73574280.0000 - val_mae: 7626.7026\n",
            "Epoch 22/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 77669024.0000 - mae: 7117.8340 - val_loss: 74138088.0000 - val_mae: 7698.6895\n",
            "Epoch 23/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 61645568.0000 - mae: 6468.2485 - val_loss: 70986944.0000 - val_mae: 7477.8804\n",
            "Epoch 24/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 65120012.0000 - mae: 6573.2568 - val_loss: 71183440.0000 - val_mae: 7532.8105\n",
            "Epoch 25/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 73320224.0000 - mae: 6964.7900 - val_loss: 72096976.0000 - val_mae: 7662.8833\n",
            "Epoch 26/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 58768260.0000 - mae: 6278.5649 - val_loss: 68531288.0000 - val_mae: 7389.0713\n",
            "Epoch 27/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 67800384.0000 - mae: 6705.1445 - val_loss: 67539592.0000 - val_mae: 7335.9912\n",
            "Epoch 28/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 59258268.0000 - mae: 6249.4004 - val_loss: 66968800.0000 - val_mae: 7316.9966\n",
            "Epoch 29/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 66613488.0000 - mae: 6597.9741 - val_loss: 64980668.0000 - val_mae: 7145.7930\n",
            "Epoch 30/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 60109424.0000 - mae: 6052.6250 - val_loss: 64742336.0000 - val_mae: 7162.8730\n",
            "Epoch 31/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 60698748.0000 - mae: 6191.2051 - val_loss: 63347388.0000 - val_mae: 7066.2632\n",
            "Epoch 32/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 53864332.0000 - mae: 5789.4868 - val_loss: 63207736.0000 - val_mae: 7095.0054\n",
            "Epoch 33/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 49789820.0000 - mae: 5500.8911 - val_loss: 60951052.0000 - val_mae: 6940.9341\n",
            "Epoch 34/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 58055684.0000 - mae: 6061.4180 - val_loss: 58850144.0000 - val_mae: 6827.0483\n",
            "Epoch 35/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 52092448.0000 - mae: 5663.2383 - val_loss: 57179136.0000 - val_mae: 6736.2480\n",
            "Epoch 36/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 56974136.0000 - mae: 6019.2017 - val_loss: 57412452.0000 - val_mae: 6803.0078\n",
            "Epoch 37/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 58500052.0000 - mae: 5919.8975 - val_loss: 55023424.0000 - val_mae: 6644.2266\n",
            "Epoch 38/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 48531372.0000 - mae: 5569.9375 - val_loss: 55875216.0000 - val_mae: 6756.6909\n",
            "Epoch 39/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 48791312.0000 - mae: 5419.6006 - val_loss: 52707252.0000 - val_mae: 6507.4189\n",
            "Epoch 40/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 47950672.0000 - mae: 5425.1675 - val_loss: 50209972.0000 - val_mae: 6291.7061\n",
            "Epoch 41/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 47978560.0000 - mae: 5596.2261 - val_loss: 51144704.0000 - val_mae: 6437.1450\n",
            "Epoch 42/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 44856096.0000 - mae: 5439.1094 - val_loss: 52311956.0000 - val_mae: 6557.5225\n",
            "Epoch 43/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 43856248.0000 - mae: 5130.8789 - val_loss: 51126756.0000 - val_mae: 6489.2065\n",
            "Epoch 44/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 37601288.0000 - mae: 4812.2729 - val_loss: 48515204.0000 - val_mae: 6296.2124\n",
            "Epoch 45/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 46621392.0000 - mae: 5241.9502 - val_loss: 46769668.0000 - val_mae: 6156.7632\n",
            "Epoch 46/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 33789056.0000 - mae: 4734.4170 - val_loss: 45983240.0000 - val_mae: 6115.5703\n",
            "Epoch 47/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 34169136.0000 - mae: 4463.6089 - val_loss: 48753920.0000 - val_mae: 6351.6123\n",
            "Epoch 48/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 33120816.0000 - mae: 4736.1807 - val_loss: 47690628.0000 - val_mae: 6270.6919\n",
            "Epoch 49/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 33857764.0000 - mae: 4665.0522 - val_loss: 43656756.0000 - val_mae: 5935.8867\n",
            "Epoch 50/50\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 30030604.0000 - mae: 4310.8599 - val_loss: 43271236.0000 - val_mae: 5910.3618\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 24956954.0000 - mae: 3939.1191\n",
            "\n",
            "✅ Final Model Test MSE (Loss): 25885166.00\n",
            "✅ Final Model Test MAE: 3942.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nDhDg5Yle9Mm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}